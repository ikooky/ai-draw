# ===================================================================
# AI 模型配置
# ===================================================================
#
# 配置一个 OpenAI 兼容的 API 端点
# 应用会自动从该端点获取可用的模型列表，并在 UI 中提供模型选择器
#
# 支持的 API：
# - OpenAI API
# - DeepSeek API
# - 通义千问 (Qwen)
# - Ollama / LM Studio / vLLM 等本地 LLM
# - 任何其他 OpenAI 兼容的 API
# ===================================================================

# CUSTOM_BASE_URL: API 基础地址 (必填)
# 应用会从 {CUSTOM_BASE_URL}/models 获取可用模型列表
CUSTOM_BASE_URL=http://localhost:1234/v1

# CUSTOM_API_KEY: API 密钥 (必填)
CUSTOM_API_KEY=your-api-key-here

# AI_MODEL: 默认模型 ID (可选)
# 如果不设置，将使用 API 返回的第一个模型
# 示例: gpt-4, gpt-4o, deepseek-chat, qwen-plus 等
AI_MODEL=gpt-4

# ===================================================================
# 配置示例
# ===================================================================

# OpenAI API:
# CUSTOM_BASE_URL=https://api.openai.com/v1
# CUSTOM_API_KEY=sk-xxx
# AI_MODEL=gpt-4

# DeepSeek API:
# CUSTOM_BASE_URL=https://api.deepseek.com
# CUSTOM_API_KEY=sk-xxx
# AI_MODEL=deepseek-chat

# 通义千问 (Qwen):
# CUSTOM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# CUSTOM_API_KEY=sk-xxx
# AI_MODEL=qwen-plus

# 本地 LLM (Ollama):
# CUSTOM_BASE_URL=http://localhost:11434/v1
# CUSTOM_API_KEY=ollama
# AI_MODEL=llama2

# 本地 LLM (LM Studio):
# CUSTOM_BASE_URL=http://localhost:1234/v1
# CUSTOM_API_KEY=lm-studio
# AI_MODEL=local-model
